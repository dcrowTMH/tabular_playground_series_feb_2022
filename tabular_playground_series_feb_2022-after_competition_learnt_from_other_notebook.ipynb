{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fecb9a",
   "metadata": {},
   "source": [
    "# Tabular Playground Series - Feb 2022\n",
    "\n",
    "This dataset is aimed to practive ML skills by using the genomic analysis technique data with some data compression and data loss.\n",
    "\n",
    "ATATGGCCTT will be represented as A2T4G2C2 instead of the sequence.\n",
    "\n",
    "Let's start with checking the data set and let's find out some direction for analysis.\n",
    "\n",
    "### Aim:\n",
    "Read the notebook from competition expert and learn the way to deal with data, model training\n",
    "\n",
    "To perform well in the training and know more about the data set, the paper for this competition was suggested to read through.\n",
    "\n",
    "https://www.frontiersin.org/articles/10.3389/fmicb.2020.00257/full\n",
    "\n",
    "The model used in the paper was Passive-Aggressive Classifier (PA, linear machine learning algorithm); Extra Trees Classifier (ET, decision tree algorithm); Gaussian Naïve Bayes (GNB, Naïve Bayes algorithm); Linear Discriminant Analysis (LDA, discriminant analysis algorithm); and the neural network (NN, whose default is 100 layers and the number of nodes determined by the number of input features).\n",
    "\n",
    "Here is some hints that we can work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02bf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries set up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f758930",
   "metadata": {},
   "source": [
    "For the preparation work, it can be compressed into few lines of code instead of few sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24bcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data, drop the duplicate and pop the target for train set\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "# read the data, drop the duplicate at the same time\n",
    "x_train = pd.read_csv(train_path, index_col = 0).drop_duplicates()\n",
    "x_test = pd.read_csv(test_path, index_col = 0)\n",
    "y_train = x_train.pop('target').to_frame()\n",
    "\n",
    "# one hot code for the target\n",
    "y_train_ohe = pd.get_dummies(y_train['target'])\n",
    "y_toname = {x:y for x,y in enumerate(y_train_ohe.columns)}\n",
    "y_toint = {y:x for x,y in enumerate(y_train_ohe.columns)}\n",
    "y_train['target_num'] = y_train['target'].map(y_toint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da971ca",
   "metadata": {},
   "source": [
    "KNN\n",
    "- As the notebook said the the performance is better without cross-validatoin. It preferred to use the full training set once & it can be observed from my previous notebook since there is no obvious change after we have implemented the cross-validation. (Experimental noise & mutations was found in the data set from the paper. The expiermental noise was appeared in both train & test set but the mutation was found in the test set)\n",
    "\n",
    "- Experimental noise (Sampling noise) was tackled with large sample size\n",
    "- Mutation (Sampling bias) was the main issue but it can/ cannot be avoided into the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f1409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# build the K-neighbors classifier model\n",
    "model = KNeighborsClassifier(n_jobs = -1, metric = 'manhattan', weights = 'distance', n_neighbors = 2)\n",
    "# fit the data into the model\n",
    "model.fit(x_train, y_train['target_num'])\n",
    "# get the probability for the prediction to check with the distribution\n",
    "y_test_prob = pd.DataFrame(model.predict_proba(x_test), index = x_test.index, columns = y_train_ohe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5472bdb",
   "metadata": {},
   "source": [
    "To get a great/ good testing set, the probabilities in all the class should be balanced. Most notebooks did this by adding different constants to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5c12f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Escherichia_fergusonii      0.10444\n",
       "Campylobacter_jejuni        0.10197\n",
       "Streptococcus_pneumoniae    0.10049\n",
       "Klebsiella_pneumoniae       0.10048\n",
       "Streptococcus_pyogenes      0.10045\n",
       "Salmonella_enterica         0.10022\n",
       "Bacteroides_fragilis        0.10003\n",
       "Enterococcus_hirae          0.09964\n",
       "Staphylococcus_aureus       0.09855\n",
       "Escherichia_coli            0.09373\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check class distribution\n",
    "# return the column index for each sample\n",
    "y_test_knn = y_test_prob.apply(lambda x: x.argmax(), axis = 1)\n",
    "# turn the index into the name\n",
    "y_test_knn = y_test_knn.map(y_toname).rename('target').reset_index()\n",
    "# return the count with relative frequency\n",
    "display(y_test_knn.target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b32fa",
   "metadata": {},
   "source": [
    "The probabilities is not that balanced especially Escherichia_coli.\n",
    "\n",
    "This part is quite confuse since the editor try to use the quantile to add on more probabilties for 10% of observation. The idea is not sure but it did a great job to balance the probabilties distribution. It work well to deal with the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "579121ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        0.500000\n",
       "Campylobacter_jejuni        0.613518\n",
       "Enterococcus_hirae          0.500000\n",
       "Escherichia_coli            0.375595\n",
       "Escherichia_fergusonii      0.534749\n",
       "Klebsiella_pneumoniae       0.505897\n",
       "Salmonella_enterica         0.500000\n",
       "Staphylococcus_aureus       0.404429\n",
       "Streptococcus_pneumoniae    0.518519\n",
       "Streptococcus_pyogenes      0.509804\n",
       "Name: 0.9, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_test_prob.quantile(0.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fad9bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide all the probabilties with 90% quantile\n",
    "y_test_prob /= y_test_prob.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7af8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 50% probability -> result the 10% of observation having more that 50% probability for each class\n",
    "y_test_prob /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c9a3b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bacteroides_fragilis        0.5\n",
       "Campylobacter_jejuni        0.5\n",
       "Enterococcus_hirae          0.5\n",
       "Escherichia_coli            0.5\n",
       "Escherichia_fergusonii      0.5\n",
       "Klebsiella_pneumoniae       0.5\n",
       "Salmonella_enterica         0.5\n",
       "Staphylococcus_aureus       0.5\n",
       "Streptococcus_pneumoniae    0.5\n",
       "Streptococcus_pyogenes      0.5\n",
       "Name: 0.9, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "354b2286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Campylobacter_jejuni        0.10082\n",
       "Streptococcus_pyogenes      0.10053\n",
       "Streptococcus_pneumoniae    0.10024\n",
       "Salmonella_enterica         0.10016\n",
       "Bacteroides_fragilis        0.10004\n",
       "Escherichia_fergusonii      0.09986\n",
       "Staphylococcus_aureus       0.09984\n",
       "Enterococcus_hirae          0.09967\n",
       "Escherichia_coli            0.09948\n",
       "Klebsiella_pneumoniae       0.09936\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_knn = y_test_prob.apply(lambda x : x.argmax(), axis = 1)\n",
    "y_test_knn = y_test_knn.map(y_toname).rename('target').to_frame()\n",
    "y_test_knn[['target']].to_csv('submission_knn.csv')\n",
    "display(y_test_knn.target.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78c875",
   "metadata": {},
   "source": [
    "After using the KNN model for the classification, the accuracy (0.98644)is very high compared to my previous model.\n",
    "\n",
    "By adjusting the result with quantile, the accuracy (0.98810) is much better.\n",
    "\n",
    "#### Thing needed to be investigated for this part:\n",
    "\n",
    "1) Why not cross-validation?\n",
    "\n",
    "2) manhattan metric & inverse-distance weights and only 2 neighbors\n",
    "\n",
    "3) Why manhattan appears to be more robust against outlier mutations than the euclidean distance (L2).\n",
    "\n",
    "4) Why use the quantile to rescale?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6062e",
   "metadata": {},
   "source": [
    "#### Another thing needed to be investigated before next part:\n",
    "    \n",
    "1) Extra tree classifier (Many notebook used it and the editor as work with it for better accuracy as well)\n",
    "\n",
    "2) GCD (Another technique used by different notebook as well)\n",
    "\n",
    "3) PCA to visualize the training set & predicted test set. (Accuracy visualization)\n",
    "\n",
    "Reference video:\n",
    "\n",
    "1) https://www.youtube.com/watch?v=1VgevfcOmyE (Extra tree classifier)\n",
    "\n",
    "2) https://www.youtube.com/watch?v=yHwneN6zJmU (Euclidean Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c736e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn-env] *",
   "language": "python",
   "name": "conda-env-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
